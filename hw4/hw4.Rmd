---
title: "STAT401_HW4"
author: "김정현"
output: word_document
---

# Q1.
```{r}
options(digits=3)
library(psych)
rmat<-matrix(
    c(1,-0.04,0.61,0.45,0.03,-0.29,-0.3,0.45,0.3,
    -0.04,1,-0.07,-0.12,0.49,0.43,0.3,-0.31,-0.17,       0.61,-0.07,1,0.59,0.03,-0.13,-0.24,0.59,0.32, 0.45,-0.12,0.59,1,-0.08,-0.21,-0.19,0.63,0.37, 0.03,0.49,0.03,-0.08,1,0.47,0.41,-0.14,-0.24, -0.29,0.43,-0.13,-0.21,0.47,1,0.63,-0.13,-0.15, -0.3,0.3,-0.24,-0.19,0.41,0.63,1,-0.26,-0.29, 0.45,-0.31,0.59,0.63,-0.14,-0.13,-0.26,1,0.4, 0.3,-0.17,0.32,0.37,-0.24,-0.15,-0.29,0.4,1),nrow = 9,ncol=9)

```

## (a)
```{r}
q1=princomp(covmat=rmat,cor=T)
summary(q1)
q1$sdev^2
screeplot(q1, npcs=6,type="l")
```

1) Choose the principal components at the total variance over 70%, then 3 PCs explain 70.2% of the total variation.

2) Choose the principal components where eigenvalues are larger than 1, then choose 2 PCs.

3) Choose the principal components based on the scree plot, then choose 3 PCs.

Therefore, we can choose 3 factors to estimate factor loadings.


## (b)
```{r}
f1 = fa(rmat, nfactors=3, fm="pa", rotate="none")
f1$communality
```

## (c)
```{r}
diag(f1$uniq)
```
## (d)
```{r}
f1$loadings[7,1]
```

Correlation between 7th statement and the first factor is -0.576.


## (e)
```{r}
rmat-f1$loadings%*%t(f1$loadings)-diag(f1$uniq)
```

We can check that our residual matrix is almost 0.


## Repeat using Varimax

```{r}
f2 = fa(rmat, nfactors=3, fm="pa", rotate="varimax")
f2$communality
```

```{r}
diag(f2$uniq)
```
Note that communalities and specific variances are same with rotate = "none" method.

```{r}
f2$loadings[7,1]
```

Correlation is -0.218, which is weaker than rotate = "none" method.

```{r}
rmat-f2$loadings%*%t(f2$loadings)-diag(f2$uniq)
```

The residual matrix is close to zero compared to rotate = "none" method.

# Q2.

```{r}
l1<-matrix(c(0.789,0.834,0.74,0.586,0.676,0.654,0.641,0.629,0.564,0.808,
-0.403,-0.234,-0.134,-0.185,-0.248,0.44,0.534,0.651,0.354,0.714),ncol = 2, nrow = 10)

fa.plot(l1,xlim=c(-1,1),ylim=c(-1,1))
abline(a=0,b=l1[1,2]/l1[1,1],col=4,lwd=2)
abline(a=0,b=-l1[1,1]/l1[1,2], col=4,lwd=2)

```

```{r}
a1<-acos(l1[1,1]/sqrt(l1[1,1]^2+l1[1,2]^2))/(2*pi)*360
cat("Angle:", a1)

```

The angle needed is 27.1.

## (b)

By this result, We can divide by (x6, x7, x8, x9, x10) and (x1, x2, x3, x4, x5) here.


# Q3.
## (a)
```{r}
s.dat <- read.csv('sales.dat', header = T, sep = '')
s.f2 <- fa(s.dat, nfactors = 2, fm = "ml", rotate = "none")
print("Communality:")
s.f2$communalities

print("Specific Variance:")
diag(s.f2$uniq)

print("Communality*Communality + Specific Variance:")
s.f2$loadings %*% t(s.f2$loadings) + diag(s.f2$uniq)
```


```{r}
s.f3 <- fa(s.dat, nfactors = 2, fm = "ml", rotate = "none")
print("Communality:")
s.f3$communalities

print("Specific Variance:")
diag(s.f3$uniq)

print("Communality*Communality + Specific Variance:")
s.f3$loadings %*% t(s.f3$loadings) + diag(s.f3$uniq)
```

## (c)
```{r}
s.f1 <- fa(s.dat, nfactors = 1, fm = "ml", rotate = "none")
s.f4 <- fa(s.dat, nfactors = 4, fm = "ml", rotate = "none")

chi1 <- function(model, nfactors) {
    chi.q <- model$STATISTIC
    prob <- model$PVAL
    cat("n =", nfactors, ": Chi Square =", chi.q, "with prob <", prob, "\n")
}

chi1(s.f1, 1)
chi1(s.f2, 2)
chi1(s.f3, 3)
```

Even though we use 3-factor model, our p-value is still smaller than 0.05, which is still significant. Also, 4-factor model is not appropriate since s < 0 in this case.

```{r}
chi1(s.f4, 4)
```
We check that 4 factor model does not work.
Therefore, we can pick 3 factor model.


## (d)
```{r}
f.ml1 = fa(s.dat, nfactors=2, n.obs=length(s.dat), fm="ml", rotate="none")
apply(f.ml1$scores, 2, mean)
apply(f.ml1$scores, 2, var)
```
Mean is close to 0 and Variance is close to 1.

## (e)
```{r}
f.ml1
```

x1, x3, x4, x5 is allocated in factor 1 and x2, x6, x7 is allocated in factor2.


```{r}
simpsum <- cbind(round(as.matrix(s.dat[,c(1,3,4,5)]),1) %*% c(1,1,1,1),
    round(as.matrix(s.dat[,c(2,6,7)]),1) %*% c(1,1,1))
simpsum
```

One can check that factor scores in (d) and (e) are different.